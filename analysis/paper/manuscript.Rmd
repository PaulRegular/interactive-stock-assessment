---
title: |
  Improving the communication and accessibility of stock assessment using interactive visualization tools
author: "Paul M. Regular, Gregory J. Robertson, Robert Rogers, Keith P. Lewis"
date: |
  Fisheries and Oceans Canada, Northwest Atlantic Fisheries Center, 80 East White Hills, St. John's, Newfoundland and Labrador, A1C 5X1, Canada
output: 
  bookdown::word_document2:
    reference_docx: template.docx
bibliography: references.bib
csl: cjfas.csl
abstract: |

  **Corresponding author**: Paul M. Regular, Fisheries and Oceans Canada, Northwest Atlantic Fisheries Center, 80 East White Hills, St. John's, Newfoundland and Labrador, A1C 5X1, Canada, E-mail: Paul.Regular@dfo-mpo.gc.ca, Phone: 1-709-772-2067
  
  **Abstract**: Scientists across many fields are faced with the challenge of synthesizing and communicating information from large and complex data sets. The field of stock assessment is no exception as the volume and variety of the data has grown alongside the computational methods used to integrate them. While this growth in data and model complexity has improved many stock assessments, the process of communicating key results to colleagues and stakeholders in a meaningful way has become more daunting. The traditional approach of presenting information across a series of static slides often fails to convey the richness of information available and, as such, important patterns and details are easily overlooked. Here we contend that this problem can be mediated through the effective use of new open source tools for building interactive visualizations. These tools allow a broader audience to conduct detailed explorations of the results, leading to a deeper and collective understanding of both the data and models used to inform stock assessments. As a consequence, the peer review process is more open and accessible.

---

*The greatest value of a picture is when it forces us to notice what we never expected to see.*  
- Tukey [-@tukey1977]


Quantitative stock assessment plays a central role in modern fisheries management [@hilborn1992]. Over time, and as new methods are developed, there is an increasing amount of data available to inform stock assessments. These data might be richer information on stock structure using an increasing array of markers and biomarkers, and/or the continued lengthening of population status and catch time series. Concurrently, analytical methods are now able to integrate many data sources into one stock assessment model [@maunder2013]. While these advances have surely improved the advice provided on stock status, it has become more difficult to communicate the basis of this advice in a meaningful way. Visualizations play a critical role in communicating this information to stakeholders [@levontin2017]. However, traditional formats (e.g. slides) are often insufficient to convey the richness of information available and the static and sequential nature of these formats can stifle meaningful discussions. A solution to this problem is the effective use of interactive visualization tools [@keena2016]. These are common tools we use every day on a range of web sites, but their use is no longer restricted to web site developers as these tools are being integrated into software commonly used by the research community [@perkel2018]. As a result, an increasing number of scientists across a wide range of disciplines are starting to apply interactive visualization tools to explore and communicate their results [e.g. @jones2016; @yeatman2018; @letcher2018]. 

Fisheries scientists are a part of this trend and, as such, there are a growing number of interactive tools available that facilitate the exploration and communication of fisheries science. For instance, they can be used to disseminate real-time information for dynamic ocean management [@hazen2018; @maxwell2015], explore hindcasts and projections from various habitat suitability models [@mchenry2019], and evaluate different fisheries management approaches [@miller2019; @goethel2019] (see Appendix A for more examples). Such tools complement static documentation as they allow audiences to explore data and models in ways not amenable to static formats and, in the process, they improve accessibility and augment communication efforts. These will be helpful tools to utilize as we proceed through an age of heightened scientific scrutiny [@mcinerny2014], and here we aim to promote their use in fisheries science by demonstrating a series of interactive visualization tools built to aid in the peer review of stock assessments. 

We first demonstrate the application of interactive tools to data that are commonly presented in stock assessments to show how they can simplify the detailed exploration of data from long-term monitoring programs. Second, we focus on the modeling aspect of stock assessment and demonstrate how interactive tools can be used to explore, diagnose, and communicate results from an integrated assessment model. This structure corresponds to two important  steps in the stock assessment process: 1) data exploration, and 2) data modeling. In both cases interactive visuals are nested inside dynamic documents called "dashboards". The concept of using a dashboard was borrowed from the business community where they are frequently used to group a series of interactive visuals and tables to provide at-a-glance views of key performance indicators. These dashboards were constructed within the framework of the R programming language [@R] and the RStudio IDE [@Rstudio] using three or more of the packages listed in Table \@ref(tab:pkg). See Supplement 1 for a "getting started" tutorial that highlights one approach to constructing a dashboard using R; using this as a guide, an R user can start constructing basic dashboards within a day.


```{r pkg, results = "asis", echo = FALSE}

## Package name and description
pkg <- c(shiny = 'Makes it incredibly easy to build interactive web applications with R. Automatic "reactive" binding between inputs and outputs and extensive prebuilt widgets make it possible to build beautiful, responsive, and powerful applications with minimal effort [@chang2018a]',
         shinydashboard = "Create dashboards with 'Shiny'. This package provides a theme on top of 'Shiny', making it easy to create attractive dashboards [@chang2018b].",
         rmarkdown = "Convert R Markdown documents into a variety of formats [@allaire2018].",
         flexdashboard = "Format for converting an R Markdown document to a grid oriented dashboard. The dashboard flexibly adapts the size of its components to the containing web page [@allaire2017].",
         plotly = "Easily translate 'ggplot2' graphs to an interactive web-based version and/or create custom web-based visualizations directly from R [@sievert2018].",
         leaflet = "Create and customize interactive maps using the 'Leaflet' JavaScript library and the 'htmlwidgets' package. These maps can be used directly from the R console, from 'RStudio', in Shiny applications and R [@cheng2018].",
         crosstalk = 'Provides building blocks for allowing HTML widgets to communicate with each other, with Shiny or without (i.e. static .html files) [@cheng2016].')

tab <- data.frame(names(pkg), unname(pkg))
names(tab) <- NULL
# names(tab) <- c("**Package**", "**Description**")
tab[, 1] <- paste0("**`", tab[, 1], "`**")

knitr::kable(tab, caption = "Names and descriptions of the key packages used to build the interactive applications presented in this paper. Descriptions are directly from the `DESCRIPTION` file of each package.")

```


# Data exploration

The data sets used in stock assessments are constantly growing due to the continuation of long-term monitoring efforts, the addition of new monitoring programs, or both. As such, stock assessment biologists need to manage large volumes of data from a variety of sources. Time series of reported landings and catch-at-age are often analyzed in conjunction with data from "fishery-independent" surveys that track changes in relative abundance and, in many cases, also monitor trends in biological factors such as age composition, growth rates, sex ratios and maturation stages. For some data-rich stocks, mark and recapture studies are also carried out to estimate movement, migration, growth rate, natural mortality, and discard mortality. All of the above-mentioned data sets are complex and, as the volume and variety of these data increases, it becomes more difficult to be aware of the details of each data set and discover key patterns within each. It has long been recognized that this challenge can be mediated, to a degree, by the application of interactive visualization tools as they allow detailed exploration of the data behind a plot [@tukey1985; @fisherkeller1988]. For instance, the ability to zoom in on features or areas of interest, turn off layers and hover over specific points to reveal more information creates an interactive user-driven experience that expedites explorations of data. These abilities are illustrated  by two recently developed interactive tools: 1) a tool designed to quickly examine fishery-independent survey data; and 2) an interactive  mapping tool developed for the exploration of a long-term tagging study.


## Survey data

Fisheries and Oceans Canada (DFO) has been conducting a multi-species stratified-random survey across the Newfoundland and Labrador shelf since the 1970s [@rideout2018]. These data are analyzed using a standard stratified analysis via a local R package called RStrap [for details on methodology see @smith1981]. Both the inputs and outputs from RStrap analyses are very large and, depending on the species, may include > 40 years and span the majority of the Newfoundland and Labrador shelf. In order for fisheries scientists to quickly and reliably explore these data without iteratively modifying R scripts one species at a time, an application (hereafter called RStrap Explorer) was built using a combination of shiny, crosstalk, flexdashboard, plotly and R markdown (Table \@ref(tab:pkg)). RStrap Explorer started as a way to visualize estimates of biomass and abundance trends of specific species by supplying RStrap output to a flexdashboard file designed to organize and visualize the results. The shiny package was latter applied as it allows RStrap to be run in the background and therefore allows the user to dynamically explore abundance and biomass estimates from multiple species in one session. Both crosstalk and plotly were incorporated to allow the user to interact with the data. 

RStrap Explorer contains four primary tabs: 1) "Survey Indices" contains stock level estimates of biomass and abundance (Figure \@ref(fig:biomass)), 2) "Age & Length Distributions" contains length and age frequency plots (Figure \@ref(fig:freq)), 3) "Recruitment" displays recruitment indices, and 4) "Help" provides additional context to the survey data and analysis. The input interface for RStrap Explorer is divided into two parts: basic and advanced inputs. Basic inputs are those like species, season, and survey year(s). Advanced inputs allow the user to define the length or age of recruitment, select whether they would like analyses conducted by length and/or age, and so on. This application was built for data exploration and allow the user to obtain quick and easy visualization of survey data, before the thorough data checking and analysis required for formal stock assessment begins. 

```{r biomass, echo = FALSE, fig.cap = '- Screen shot of the "Survey Indices" page of the RStrap Explorer application. The "Basic Inputs" sidebar is fixed across all pages and allows the user to specify the species, NAFO Divisions, season, and survey years of interest. The "Biomass Index" sub-tab is illustrated here. This sub-tab shows a time-series of biomass data with 95% confidence intervals, with a break in the lines when the survey gear changed from an Engle to Campelen trawl, for both cod (*Gadus morhua*; species code 438) and American Plaice (*Hippoglossoides platessoides*; species code 889). All trend lines can be toggled off using plotly’s dynamic user interface.'}
knitr::include_graphics("figures/RStrap_dashboard_biomass.png")
```


```{r freq, echo = FALSE, fig.cap = '- "Age and Length Frequencies" tab of the RStrap Explorer tool. This tab illustrates the length frequency distributions of both cod (*Gadus morhua*; species code 438) and American plaice (*Hippoglossoides platessoides*; species code 889) binned into 2 cm length bins. The binning is easily modified using the "Length Group" field in the "Advanced Options" drop down menu (shown on left side).'}
knitr::include_graphics("figures/RStrap_dashboard_freq.png")
```


## Tagging data

Northern cod (NAFO Divisions 2J3KL) has a rich history of tagging, starting as a dedicated program in 1954 [@taggart1995] and continuing to this day. The tagging and recovery data are captured in a standardized database, with fields typical of most tagging programs. This database has over 600,000 records as of early 2019, with 2,000-10,000 tags deployed annually in recent decades. The tagging and recovery data are used in the current assessment model for this stock [@cadigan2016], but tools to explore this extensive data set were limited, especially from a spatial perspective. To begin to explore and understand this large data set, we built a simple application using shiny and leaflet (Table \@ref(tab:pkg)) that allows a user to quickly and dynamically subset the data (e.g. ranges of tag release and tag recovery years, specific geographic locations). As the application developed, it was incorporated into shinydashboard, to take advantage of the number of layout options available in shinydashboard (Table \@ref(tab:pkg)). Given the large number of tags released, often at nearby sites, visualizing the data with static mapping was particularly challenging. The markercluster (https://github.com/Leaflet/Leaflet.markercluster) function available in leaflet was particularly useful as a means to dynamically scale the level of pooling of spatial points (Figure \@ref(fig:map)). This basic mapping tool allowed us to quickly become familiar with the data, identify outliers and incorrect data entries, as well as explore options on how to spatially pool the data for subsequent demographic analysis. Further tabs were added to provide basic summaries of the selected data (Figure \@ref(fig:summary)).

```{r map, echo = FALSE, fig.cap = 'A screen shot of cod tag mapping tool using shinydashboard and leaflet. The markercluster function dynamically splits or pools tagging locations (red, orange, green or yellow points) depending on zoom level, the recovery positions (blue) are much fewer, and are left to be plotted individually at all scales. Options to include pop up labels are included, so specific information on each point can be retrieved with a mouse click (in this case: tag number, fish length, date released, and date recovered), which is particularly useful when error checking.'}
knitr::include_graphics("figures/tagging_dashboard_map_tab.png")
```


```{r summary, echo = FALSE, fig.cap = 'Basic summaries of the recovery data from the tags selected within the shiny dashboard cod tag mapping tool. In this case, histograms and summary statistics of the recovery positions are returned, along with a simple map of kernels showing the spatial distribution of the selected tag recoveries.'}
knitr::include_graphics("figures/tagging_dashboard_summary_tab.png")
```


# Data modeling

Synthesizing data from multiple sources presents a key challenge to stock assessment. Analyses of different data sources were traditionally carried out independently and the summaries or parameters from these analyses were used in the assessment model. This approach, however, is less than ideal because information may be lost and uncertainty may be unaccounted for when we "do statistics on the statistics" [@link1999; @maunder2013]. ). Such issues have largely been curtailed in contemporary stock assessments as advances in statistical computing have enabled integrated analyses of data from multiple monitoring programs [@maunder2013]. Specifically, statistical modeling tools such as JAGS [@plummer2003], AD Model Builder [@fournier2012], and Template Model Builder [TMB; @kristensen2015] allow the construction of a joint likelihood for an array of observations to, in theory, extract as much information as possible about the biological and fishery processes. From a computational perspective, analyses of a variety of large data sets has never been easier. However, from a human perspective, contemporary stock assessment biologists are faced with the challenge of understanding and integrating data from multiple sources into a single model and communicating the methods and results to stakeholders and fisheries managers. This challenge was palpable for the data-rich case of Northern cod.

The Northern cod stock off southern Labrador and eastern Newfoundland is one of the most well studied stocks in eastern Canada. As such, there are multiple monitoring programs that help inform the status of the stock and data from most of these programs have been integrated into a state-space stock assessment model, called NCAM [@cadigan2016]. The model includes information from research vessel autumn trawl surveys (1983-present), Sentinel fishery surveys (1995-present), inshore acoustic surveys (1995-2009), fishery catch-at-age compositions, and reported fishery landings (1983-present), and tagging (1983-present). Using a series of observation equations, this TMB based model simplifies thousands of data points into quantities such as annual recruitment, spawning stock biomass, fishing mortality, and natural mortality. Once the model is fit to the data, the next step is to produce visual representations of the data and model output. The traditional approach would involve producing static presentations and documents with a series of figures and tables.  However, with numerous model inputs and outputs, this approach quickly becomes overwhelming for both the analyst and the stakeholders involved for at least two reasons. First, it is no longer feasible for the analyst to include and describe every figure and table produced in a single document. Second, it is difficult for stakeholders to efficiently digest the information that has been compressed into a series of static slides or pages. Interactive documents provide a potential solution to this problem as they allow much more information to be contained and accessible on a single screen. 

In the pursuit of an easier and more efficient way to communicate results from NCAM, an interactive "dashboard", called NCAM explorer, was developed for the 2018 assessment of Northern cod [@dwyer2019]. We used R-based packages (Table \@ref(tab:pkg)) to construct a tool for exploring the input and output of NCAM, specifically the flexdashboard package to group interactive plotly-based visuals into a dynamic document. We also used the crosstalk package to link the data displayed across multiple plots. Via R Markdown, the dashboard is rendered into a self-contained html file that is reproducible, interactive, and easy to update following modifications to the model or the addition of new data. The intent of this tool was not to replace detailed documentation on the model [i.e. @cadigan2016; @dwyer2019], however, it was built to serve as an interactive alternative to a standard presentation for communicating the latest results to an audience with a working knowledge of the stock and assessment model. Explanatory text and detail were therefore kept to a minimum, allowing the audience to explore the figures and data unencumbered by verbose descriptions.

The NCAM dashboard (Supplement 2) contains a series of pages, the first of which provides terse point-form background on the model (page named "Background"). Subsequent pages provide a series of diagnostic plots for assessing model fits to catch ("Landings"; accessed from the "Fishery" drop-down menu), survey ("RV survey", "SN survey" and "SS survey"; accessed from the "Surveys" drop-down menu), and tagging ("Tagging") data. For instance, the "RV survey" page includes plots of observed and predicted values of mean numbers per tow captured in the research vessel survey (Figure \@ref(fig:rv)). The dashboard also includes pages focused on model estimates such as selectivity ("Selectivity"; accessed from the "Fishery" drop-down menu) and catchability ("Catchability"; accessed from the "Surveys" drop-down menu). Pages for viewing trends in various population parameters are included under the "Trends" drop-down menu, where the "Retrospective analysis" page displays results from a retrospective analysis, the "Model comparison" page displays population trends from different model runs, the "Status and rates" page displays trends in stock size and vital rates (Figure \@ref(fig:trends)), and the "Productivity" page focuses on trends in Spawning Stock Biomass (SSB) and recruitment. Finally, details on the projections are accessed from the "Projections" drop-down menu ("Assumptions", "Past projections", "Retro projections", and "Results" pages), and key inputs and outputs are accessed from "Tables" drop-down menu ("Inputs", "Settings", "Outputs" pages). The plots and tables included in the dashboard are similar to those typically presented at assessment meetings and in research documents. However, there are two key benefits of this approach over the *modus operandi* of producing static documents and slides.  First, interactive plots nested in a dashboard permit relatively easy and efficient access to the details as it replaces scrolling through tens, if not hundreds, of pages or slides with mouse-clicks across a smaller number of dynamic pages holding data-rich illustrations (i.e. both broader patterns and finer details in the data are accessible via zooming and tooltips).  Second, the automated nature of the dashboard circumvents the monotonous, time-consuming and error-prone task of copying and pasting figures, tables, and values into documents and slides, although, we note that this issue can be addressed through other approaches (e.g. slide shows can easily be made using R markdown). Both benefits expedite the process of exploring a range of model configurations as the automated output facilitate quick views of standard diagnostics and the interactive plots facilitate detailed explorations and comparisons of models with different configurations. For instance, explorations of the residual plots in the dashboard allowed the authors to quickly identify conflicts between two surveys used in the model. Potential solutions to this problem were then explored by modifying the configuration of the model and these changes were quickly evaluated using a dashboard that is produced in seconds.

The dashboard also makes it easy to share the results with colleagues and stakeholders as it is rendered into a self-contained html file. This allows others to independently scrutinize details of both data and the model that are typically only accessible to the analyst. Such access improves the transparency of the stock assessment model which, in turn, leads to richer discussion and scrutiny of the biological and statistical rigor of the model. For instance, visualizations depicting the model assumptions, process errors and confidence intervals around the projections raised important questions on the impact of the assumptions on the projections from the model. These questions were raised during the first assessment meeting in which this tool was used and the ensuing discussions left us with the impression that this tool helped the assessment biologists, academics, resource managers, and fisheries representatives in the room gain a deeper understanding of the uncertainties and the patterns in the risk tables. Feedback and personal testimony from multiple stakeholders who have used the dashboard reaffirmed our impression that the tool is helpful as there was general agreement that access to the details eases communication and relieves any potential concerns that something is hidden.




```{r rv, echo = FALSE, fig.cap = 'Screenshot of the "RV survey" tab from the NCAM dashboard where total observed (dots) and NCAM model predicted values (lines) for the DFO RV survey index are shown in the left panel and standardized log residuals by year, cohort, age, and expected value (dots), with lowess curves (lines), are shown in the right panel.'}
knitr::include_graphics("figures/NCAM_dashboard_rv-survey_tab.png")
```


```{r trends, echo = FALSE, fig.cap = 'Screenshot of the "Trends" tab which displays stock status estimates (abundance, biomass, and biomass relative to B~lim~ [average biomass through the 1980s]) on the left panel, and mortality rates (average F, M, and Z) on the right panel.'}
knitr::include_graphics("figures/NCAM_dashboard_trends_tab.png")
```


# From bespoke to general tools

The interactive tools highlighted here were custom built to solve data visualization challenges that are common to many fisheries management organizations but the solutions presented are specific to the Northwest Atlantic Fisheries Centre. The concept is therefore broadly applicable, however, the underlying code will require modifications to accommodate region and stock specific data management and modelling approaches. Even within our own region, different approaches and needs meant that the code behind NCAM explorer (Supplement 2) required modifications when applied to a model developed for another cod stock. Nevertheless, considerable chunks of code were recycled and, in the process, new features were added to allow the visualization of multiple model configurations within the one dashboard. Additionally, a French colleague is currently modifying the tool to visualize output from SAM, a state-space stock assessment model widely used to assess ICES stocks [@nielsen2014]. Likewise, the concept behind RStrap Explorer and the tagging tool could be applied to other regions and the most efficient approach may be to build upon existing general frameworks [e.g. StoX software; @johnsen2019]. These are, of course, early days in the development and application of interactive tools to stock assessment. Because the tools we highlight are themselves general, flexible, and accessible, we suspect that bespoke applications will continue to be developed in parallel with more general stock assessment dashboards depending on user needs and preferences. Regardless of the approach, a common goal is to make the workflow more efficient, reproducible, and transparent.

# Towards open stock assessment

The amount of data available to scientists has grown by orders of magnitude in recent decades as has the complexities of data management, exploratory data analysis, formal analyses and associated diagnostics [@lewis2018]. The majority of this sequence of events, sometimes called "the data pipeline" [@leek2015a], have not traditionally been part of the peer-review process which sees only the end products of an analysis. However, decisions made along the data pipeline increasingly influence the outcome of the study. Gelman and Loken [-@gelman2014] coined the term "garden of forking paths" to illustrate that different conclusions can be arrived at depending on what decisions are made during different stages of the analysis. Due to a number of limitations, such as available pages in journals, much of the data pipeline is not transparent nor is it reproducible. A number of authors have recently advocated for a culture of open science and reproducible research, i.e., a change in the transparency and reproducibility of science [@leek2015a; @leek2015b; @hampton2013; @hampton2015]. Proponents of open science and reproducible research highlight a number of benefits including a more productive and responsible scientific culture, an ability to address larger and more complex questions, as well as a more efficient workflow and ability to reproduce one’s own work [@fomel2009; @lowndes2017].

A culture of openness is actively evolving in the field of stock assessment and, at this point, it is not hard to picture a future where it is commonplace for the full data pipeline to be open and accessible. Open resources are actively being developed and used to improve accessibility to all the data, methods and results that feed into stock assessments [e.g. the Transparent Assessment Framework, https://taf.ices.dk/app/about; @magnusson2020]. Likewise, tools are being developed to facilitate the creation of reproducible advisory documents [e.g. @ices2018; @anderson2020; @regular2020], and these documents can be interactive, as is the case for the VISA tool [@ices2018], or they can be supplemented by interactive tools. There is plenty of opportunity for synergies between these initiatives, as most are being developed using R, and all details and decisions can be traceable and accessible using an online repository such as GitHub. We therefore foresee a future where stock assessments become increasingly open and reproducible.

Providing open access to code and data, however, does not necessarily make a stock assessment more accessible. We believe that interactive tools, such as those presented here and in Appendix A, represent an important step forward in terms of open science as they make the peer review process more efficient. Although these tools do not reveal the entire data pipeline, a wide range of stakeholders and scientists can easily access and review details of an analysis without running a line of code. For most participants of a stock assessment, even if the entire pipeline was completely open, the details would remain inaccessible simply because most participants are already overcommitted [@banks2011] and do not have the time to fully review and recreate a particular analysis in its entirety. Further, in the case of NCAM, considerable statistical experience and expertise is required simply to run the model. However, the dashboard approach removes many of these obstacles. The html file contains all model inputs, outputs and diagnostics in an open, and easy to use, interactive document that can be distributed prior to meetings.  As such, participants can assess the results and diagnostics at their leisure. Specific experience with the tools used to generate the results are not required to constructively and critically review the results presented in the dashboard.


# Conclusions

Visualizations play an important role in communicating fisheries science to a wide range of stakeholders [@levontin2017] and here we posit that interactive tools extend the utility of data visualizations by providing a richer approach to communicating scientific information. However, we must acknowledge there are costs to adopting the use of interactive tools. The first and obvious one being that staff are required to have both the time and training to effectively develop these tools. Ideally, professional programmers and graphic designers would be hired to construct dashboards and other interactive info-graphics [@mcinerny2014], but fisheries management organizations rarely have the resources to fund such initiatives. Consequently, the process of communicating fisheries science tends to be the responsibility of fisheries scientists who lack formal training in these fields. In our three examples, the developers (first, second and third authors) were relatively proficient with R and have natural aptitudes for programming and graphic design, but all had their formal training in field-based population ecology. While some learning time was needed, the learning curve was relatively minor because there was no need to learn a new programming language (e.g. JavaScript, CSS, etc.). We can confirm that an R user can construct a basic dashboard within a day, using Supplement 1 as a guide, and a more custom dashboard in a matter of weeks. Moreover, a growing user base means that most programming issues can be readily addressed through simple internet searches. There are also a growing number of exemplars (Appendix A), beyond what we show here, to inspire the development of new interactive tools. Once over the initial learning curve, the time investment may not be much greater than one would invest into a standard presentation. We expect the accessibility and quality of these tools to continue to improve as more people in the fisheries community develop and use interactive documents. It is our experience that the upfront time investment has been worthwhile considering the improved efficiency of delivering products for subsequent stock assessments, and in the quality of the data exploration and understanding.

# Acknowledgements

We thank the numerous colleagues and participants of various stakeholder and stock assessment meetings who encouraged us to further develop these interactive visualization tools, and especially those who took the time to make suggestions on how to make them more accessible and useful. We are also grateful for the constructive feedback from Gary Carvalho, Kelli Johnson, Colin Millar, Daniel Goethel and seven anonymous reviewers.

All code used to generate this paper, Supplement 1 (getting started dashboard) and Supplement 2 (NCAM explorer) are available at https://github.com/PaulRegular/interactive-stock-assessment.


# Appendix A

Partial list of applications developed to explore and communicate marine and fisheries science:

- Marine Aggregates Application (https://openscience.cefas.co.uk/ma_tool/); a benthic-focused tool to assist with marine license application and compliance monitoring.
- Species Dashboard (https://shiny.marine.ie/speciesdash/); a tool for exploring biological fisheries data collected in Irish waters
- The Stock Book (https://shiny.marine.ie/stockbook/); a tool for accessing up-to-date information on the status of fish stocks in Irish waters.
- Data-Limited Fisheries Toolkit demo (https://www.datalimitedtoolkit.org/demo); an application for demonstrating the key features of the management strategy evaluation toolkit.
- Toy Tuna MSE application (https://puntapps.shinyapps.io/tunamse/); a toy MSE example built to allow users to enter various management procedures and assess their performance.
- Exploring Groundfish in an Ecosystem Context (https://incorporatingecosystemapproach.shinyapps.io/indiapp/); a tool accessing results from an analysis exploring links between stock indices and ecosystem trends.
- EcoCast Explorer (https://coastwatch.pfeg.noaa.gov/ecocast/explorer.html); an application for displaying results from a dynamic ocean management tool focused on bycatch avoidance [see @hazen2018 for more detail].
- B-VBGM! Bayesian Von Bertalanffy Growth Model tool (https://fishecology.shinyapps.io/B-VBGM/); a supplement Catalán et al. [-@catalan2018] that facilitates the exploration of the model described in the paper.
- Beyond Temperature tool (https://heatherwelch.shinyapps.io/beyond_temperature/); a supplement to McHenry et al. [-@mchenry2019] that allows the exploration of habitat suitability hindcasts and projections by species and model type.
- BRSApp (https://catalinagomez.shinyapps.io/BRSApp/); a supplement to Gomez et al. [-@gomez2016] that allows the exploration of behavioural response severity scores of marine mammals to noise.
- VISA tool (e.g. https://ices-tools-dev.github.io/VISA_tool/hke.27.3a46-8abd.html#ices_advice_2018); an alternative to pdf files for displaying and exploring up-to-date ICES advice [developed to meet an "EU request on dissemination of ICES advice beyond pdf files"; @ices2018].

# References
